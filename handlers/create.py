import os
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputSticker
from telegram.ext import ContextTypes, ConversationHandler
from telegram.error import BadRequest
from PIL import Image
import traceback

import emoji
import random
from tg_stickers_bot.utils import sanitize_pack_name, log_error, log_info
from tg_stickers_bot.database import add_user_photo, add_user_video, add_sticker_pack, get_and_increment_video_counter, \
    get_and_increment_photo_counter
from tg_stickers_bot.config import BOT_USERNAME
from photo.processing.briaai import remove_background_briaai
from photo.processing.rembg import remove_background_from_image
from photo.processing.u2net import remove_background_u2net, u2net_model, save_u2net_result
from moviepy.editor import VideoFileClip

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
USER_MEDIA_DIR = os.path.join(BASE_DIR, 'user_media')
IMAGE_BASE_DIR = os.path.join(USER_MEDIA_DIR, 'images')
VIDEO_BASE_DIR = os.path.join(USER_MEDIA_DIR, 'videos')

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
from tg_stickers_bot.states import (
    AWAITING_PACK_NAME,
    PROCESSING_STICKERS,
    AWAITING_EMOJI,
    EDITING_PHOTOS,
    AWAITING_PRIVACY, PROCESSING_MEDIA, VIDEO_VALIDATION, EDITING_STICKERS, AWAITING_IMAGE_SELECTION
)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —ç–º–æ–¥–∑–∏
all_emojis = list(emoji.EMOJI_DATA.keys())
# –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ RANDOM_EMOJIS (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω–æ—á–Ω—ã–µ —ç–º–æ–¥–∑–∏)
RANDOM_EMOJIS = [e for e in all_emojis if len(e) == 1]

async def process_image_with_briaai(image_path):
    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ briaai.py
    result_path = remove_background_briaai(image_path)
    return result_path

async def process_image_with_briaai_tool(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–∂–∏–¥–∞–π—Ç–µ...")
    image_path = context.user_data.get('processing_image_path')
    output_path = image_path.replace('.png', '_briaai.png')
    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ briaai.py
    remove_background_briaai(image_path, output_path)
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ user_data
    idx = context.user_data.get('processing_image_index')
    context.user_data['image_files'][idx] = output_path
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏
    with open(output_path, 'rb') as img:
        await context.bot.send_photo(
            chat_id=update.effective_chat.id,
            photo=img,
            caption="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='image_processing_done')],
                [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_image_processing')]
            ])
        )

async def create_new_pack(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    try:
        query = update.callback_query
        await query.answer()

        maximum_name_length = 64 - len('_by_') - len(BOT_USERNAME)

        hints_message = f"""–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∏–∫–µ—Ä–æ–≤ –≤ –ø–∞–∫–µ:
- –î–æ 120 —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∏–∫–µ—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –Ω–∞–±–æ—Ä–µ.
- –î–æ 50 –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∏–∫–µ—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –Ω–∞–±–æ—Ä–µ.

–†–∞–∑–º–µ—Ä —Å—Ç–∏–∫–µ—Ä–æ–≤:
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —Å—Ç–∏–∫–µ—Ä–∞ ‚Äî 512 –ö–ë.
- –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî 512x512 –ø–∏–∫—Å–µ–ª–µ–π.

–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞:
- –î–ª–∏–Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ ({maximum_name_length}) —Å–∏–º–≤–æ–ª–æ–≤.
"""

        keyboard = [
            [InlineKeyboardButton("–Ø –ø–æ–Ω—è–ª, –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å", callback_data='continue')]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(hints_message, reply_markup=reply_markup)
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –≤ create_new_pack: {str(e)}", traceback.format_exc())
        await update.effective_message.reply_text('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —Ä–µ–∂–∏–º–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.')

async def handle_mode_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        query = update.callback_query
        await query.answer()

        if query.data == 'continue':
            await query.edit_message_text('–ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ –≤–∞—à–∏ —Å—Ç–∏–∫–µ—Ä—ã.')
            context.user_data['mode'] = 'single'
            context.user_data['photo_count'] = 0
            context.user_data['video_count'] = 0
            context.user_data['document_count'] = 0
            context.user_data['image_files'] = []
            context.user_data['video_files'] = []
            return PROCESSING_STICKERS
        elif query.data == 'create_pack':
            context.user_data['emojis'] = []
            context.user_data['current_image'] = 0
            await prompt_for_emoji(update, context)
            return AWAITING_EMOJI
        elif query.data == 'edit_stickers':
            await edit_stickers(update, context)
            return EDITING_STICKERS
        elif query.data == 'process_media':
            await process_media_menu(update, context)
            return PROCESSING_MEDIA
        elif query.data == 'cancel':
            await query.edit_message_text('–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–æ.')
            context.user_data.clear()
            return ConversationHandler.END
        else:
            await query.edit_message_text('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞.')
            return ConversationHandler.END
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –≤ handle_mode_selection: {str(e)}", traceback.format_exc())
        await update.effective_message.reply_text('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —Ä–µ–∂–∏–º–∞.')
        return ConversationHandler.END

# –£–¥–∞–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è process_zip –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏

from moviepy.editor import VideoFileClip

def convert_mp4_to_webm(input_path: str, output_path: str) -> str:
    try:
        with VideoFileClip(input_path) as clip:
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 3 —Å–µ–∫—É–Ω–¥, –µ—Å–ª–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–æ–ª—å—à–µ 3 —Å–µ–∫—É–Ω–¥
            if clip.duration > 3:
                clip = clip.subclip(0, 3)

            # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–±–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
            max_dimension = max(clip.w, clip.h)
            if max_dimension > 512:
                scale_factor = 512 / max_dimension
                clip = clip.resize(scale_factor)
            # –ï—Å–ª–∏ –æ–±–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è <= 512, –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∫–∞–¥—Ä–æ–≤ –¥–æ 30 FPS
            clip = clip.set_fps(30)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ WebM —Å –∫–æ–¥–µ–∫–æ–º VP9 –∏ –±–µ–∑ –∑–≤—É–∫–∞
            clip.write_videofile(
                output_path,
                codec='libvpx-vp9',  # –ö–æ–¥–µ–∫ VP9
                audio=False,         # –û—Ç–∫–ª—é—á–∞–µ–º –∑–≤—É–∫
                threads=12,          # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                preset='medium',     # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞/—Å–∫–æ—Ä–æ—Å—Ç–∏
                bitrate='256k',      # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                ffmpeg_params=['-pix_fmt', 'yuva420p']  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª
            )

        # –ü–æ–ª—É—á–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        props = get_video_properties(output_path)
        log_info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {props}")

        return output_path
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ MP4 –≤ WebM: {str(e)}")
        raise






async def process_media(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    user_id = update.effective_user.id
    user_image_dir = os.path.join(IMAGE_BASE_DIR, str(user_id))
    user_video_dir = os.path.join(VIDEO_BASE_DIR, str(user_id))
    os.makedirs(user_image_dir, exist_ok=True)
    os.makedirs(user_video_dir, exist_ok=True)

    mode = context.user_data.get('mode', 'multi')  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–µ–∂–∏–º 'multi'

    if mode != 'single':
        return PROCESSING_STICKERS

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –µ—â—ë –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
    context.user_data.setdefault('image_files', [])
    context.user_data.setdefault('video_files', [])
    context.user_data.setdefault('photo_count', 0)
    context.user_data.setdefault('video_count', 0)

    if update.message.photo:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –¥–ª—è —Ñ–æ—Ç–æ
        counter = get_and_increment_photo_counter(user_id)
        if counter is None:
            await update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π.')
            return PROCESSING_STICKERS

        photo_name = f'{user_id}_{counter}.png'
        photo_path = os.path.join(user_image_dir, photo_name)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ
        file = await context.bot.get_file(update.message.photo[-1].file_id)
        temp_file_path = os.path.join(user_image_dir, f'temp_{user_id}.jpg')
        await file.download_to_drive(temp_file_path)

        img = Image.open(temp_file_path)
        img.thumbnail((512, 512))
        img.save(photo_path, 'PNG')

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.remove(temp_file_path)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        add_user_photo(user_id, photo_path, photo_name)

        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context.user_data['image_files'].append(photo_path)
        context.user_data['photo_count'] += 1
        await update.message.reply_text('–§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.')
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç—Ä–µ–º—è –º–µ—Ç–æ–¥–∞–º–∏
        #process_image_with_briaai_tool(photo_path, context.user_data['image_files'])
        process_image_with_rembg_tool(photo_path)
        process_image_with_u2net_tool(photo_path)

    elif update.message.video or (update.message.document and update.message.document.mime_type.startswith('video/')):
        # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –≤–∏–¥–µ–æ
        counter = get_and_increment_video_counter(user_id)
        if counter is None:
            await update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –≤–∏–¥–µ–æ.')
            return PROCESSING_STICKERS

        video_name = f'{user_id}_{counter}.webm'
        video_path = os.path.join(user_video_dir, video_name)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
        file_id = update.message.video.file_id if update.message.video else update.message.document.file_id
        file = await context.bot.get_file(file_id)
        temp_file_path = os.path.join(user_video_dir, f'temp_{user_id}_{counter}.mp4')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
        await file.download_to_drive(temp_file_path)

        try:
            convert_mp4_to_webm(temp_file_path, video_path)
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            os.remove(temp_file_path)
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            add_user_video(user_id, video_path, video_name)
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context.user_data['video_files'].append(video_path)
            context.user_data['video_count'] += 1
        except Exception as e:
            await update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –≤–∏–¥–µ–æ.')
            log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}")
            return PROCESSING_STICKERS

    else:
        await update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≤–∏–¥–µ–æ.')
        return PROCESSING_STICKERS

    # –í —Ä–µ–∂–∏–º–µ 'single' –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏ –º–µ–Ω—é
    total_count = context.user_data.get('photo_count', 0) + context.user_data.get('video_count', 0)
    photo_count = context.user_data.get('photo_count', 0)
    video_count = context.user_data.get('video_count', 0)

    keyboard = [
        [InlineKeyboardButton("–°–æ–∑–¥–∞—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫", callback_data='create_pack')],
        [InlineKeyboardButton("–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏–∫–µ—Ä—ã", callback_data='edit_stickers')],
        [InlineKeyboardButton("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–∏–¥–µ–æ", callback_data='process_media')],  # –ò–∑–º–µ–Ω–µ–Ω–æ
        [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel')]
    ]

    reply_markup = InlineKeyboardMarkup(keyboard)

    status_text = (
        f"{total_count} —Å—Ç–∏–∫–µ—Ä–∞ –ø–æ–ª—É—á–µ–Ω–æ. –ò–∑ –Ω–∏—Ö {photo_count} —Ñ–æ—Ç–æ –∏ {video_count} –≤–∏–¥–µ–æ. "
        f"–î–æ–±–∞–≤—å—Ç–µ –µ—â—ë —Ñ–∞–π–ª—ã –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–∞–ª—å–Ω–µ–π—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    )

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ –º–µ–Ω—é
    status_message = await update.message.reply_text(status_text, reply_markup=reply_markup)
    context.user_data['status_message_id'] = status_message.message_id

    return PROCESSING_STICKERS

async def handle_process_images_button(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    image_files = context.user_data.get('image_files', [])
    if not image_files:
        await query.edit_message_text('–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.')
        return PROCESSING_STICKERS

    for idx, image_path in enumerate(image_files):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        briaai_path = image_path.replace('.png', '_briaai.png')
        rembg_path = image_path.replace('.png', '_rembg.png')
        u2net_path = image_path.replace('.png', '_u2net.png')

        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é BriaAI
            remove_background_briaai(image_path, briaai_path)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é RemBG
            remove_background_from_image(image_path, rembg_path)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é U2Net
            mask = remove_background_u2net(image_path, u2net_model)
            save_u2net_result(image_path, mask, u2net_path)

        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {str(e)}", traceback.format_exc())
            await query.edit_message_text(f'–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {os.path.basename(image_path)}.')
            return PROCESSING_STICKERS

    await query.edit_message_text('–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.')
    # –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    return await initiate_image_selection(update, context)

import re
from telegram import InputMediaPhoto

async def initiate_image_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['current_selection_index'] = 0
    context.user_data['selected_images'] = []
    return await present_image_selection(update, context)

async def present_image_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    current_index = context.user_data['current_selection_index']
    image_files = context.user_data['image_files']

    if current_index >= len(image_files):
        # –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã–±—Ä–∞–Ω—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞
        await create_pack_with_selected_images(update, context)
        return ConversationHandler.END

    image_path = image_files[current_index]
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫:
    # image_path_briaai.png, image_path_rembg.png, image_path_u2net.png
    briaai_path = image_path.replace('.png', '_briaai.png')
    rembg_path = image_path.replace('.png', '_rembg.png')
    u2net_path = image_path.replace('.png', '_u2net.png')

    media = []
    try:
        with open(briaai_path, 'rb') as img1, open(rembg_path, 'rb') as img2, open(u2net_path, 'rb') as img3:
            media.append(InputMediaPhoto(media=img1, caption='BriaAI'))
            media.append(InputMediaPhoto(media=img2, caption='RemBG'))
            media.append(InputMediaPhoto(media=img3, caption='U2Net'))
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {str(e)}", traceback.format_exc())
        await update.effective_message.reply_text('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.')
        return ConversationHandler.END

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ –≥—Ä—É–ø–ø—É –º–µ–¥–∏–∞
    await context.bot.send_media_group(chat_id=update.effective_chat.id, media=media)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    keyboard = [
        [
            InlineKeyboardButton("BriaAI", callback_data=f'select_image_{current_index}_briaai'),
            InlineKeyboardButton("RemBG", callback_data=f'select_image_{current_index}_rembg'),
            InlineKeyboardButton("U2Net", callback_data=f'select_image_{current_index}_u2net'),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", reply_markup=reply_markup)
    return AWAITING_IMAGE_SELECTION

async def handle_image_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    match = re.match(r'select_image_(\d+)_(briaai|rembg|u2net)', data)
    if not match:
        await query.edit_message_text("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä.")
        return AWAITING_IMAGE_SELECTION

    index = int(match.group(1))
    tool = match.group(2)

    image_path = context.user_data['image_files'][index]
    selected_image_path = image_path.replace('.png', f'_{tool}.png')

    context.user_data['selected_images'].append(selected_image_path)
    context.user_data['current_selection_index'] = index + 1

    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    return await present_image_selection(update, context)

async def create_pack_with_selected_images(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    selected_images = context.user_data['selected_images']
    context.user_data['image_files'] = selected_images  # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–∫–µ—Ç–∞
    # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    del context.user_data['selected_images']
    del context.user_data['current_selection_index']
    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞ –∫–∞–∫ –æ–±—ã—á–Ω–æ
    await prepare_stickers_for_pack(update, context)


async def edit_stickers(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    total_files = image_files + video_files
    if not total_files:
        await update.effective_message.reply_text('–ù–µ—Ç —Å—Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.')
        return PROCESSING_STICKERS

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —Å—Ç–∏–∫–µ—Ä—ã —Å –Ω–æ–º–µ—Ä–∞–º–∏
    for idx, sticker_path in enumerate(total_files):
        if idx < len(image_files):
            with open(sticker_path, 'rb') as img:
                await context.bot.send_photo(
                    chat_id=update.effective_chat.id,
                    photo=img,
                    caption=f'–°—Ç–∏–∫–µ—Ä #{idx + 1}'
                )
        else:
            with open(sticker_path, 'rb') as video_file:
                await context.bot.send_video(
                    chat_id=update.effective_chat.id,
                    video=video_file,
                    caption=f'–°—Ç–∏–∫–µ—Ä #{idx + 1}'
                )

    await update.effective_message.reply_text('–ö–∞–∫–æ–π —Å—Ç–∏–∫–µ—Ä –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å? –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Å—Ç–∏–∫–µ—Ä–∞.')
    return EDITING_STICKERS

async def handle_sticker_edit(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    text = update.message.text.strip()
    if text.isdigit():
        sticker_number = int(text) - 1
        image_files = context.user_data.get('image_files', [])
        video_files = context.user_data.get('video_files', [])
        total_files = image_files + video_files
        if 0 <= sticker_number < len(total_files):
            context.user_data['sticker_to_edit'] = sticker_number
            if sticker_number < len(image_files):
                context.user_data['edit_type'] = 'image'
            else:
                context.user_data['edit_type'] = 'video'
            await update.message.reply_text('–û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–≤–æ–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≤–∏–¥–µ–æ –¥–ª—è –∑–∞–º–µ–Ω—ã.')
            return EDITING_STICKERS
        else:
            await update.message.reply_text('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç–∏–∫–µ—Ä–∞.')
            return EDITING_STICKERS
    else:
        await update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Å—Ç–∏–∫–µ—Ä–∞.')
        return EDITING_STICKERS

async def handle_new_sticker(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        sticker_number = context.user_data.get('sticker_to_edit')
        edit_type = context.user_data.get('edit_type')
        if sticker_number is None or edit_type is None:
            await update.message.reply_text('–ù–µ –≤—ã–±—Ä–∞–Ω –Ω–æ–º–µ—Ä —Å—Ç–∏–∫–µ—Ä–∞ –¥–ª—è –∑–∞–º–µ–Ω—ã.')
            return EDITING_STICKERS

        if update.message.photo and edit_type == 'image':
            file = await context.bot.get_file(update.message.photo[-1].file_id)
            file_path = f'images/sticker_{sticker_number}.jpg'
            await file.download_to_drive(file_path)

            img = Image.open(file_path)
            img.thumbnail((512, 512), Image.ANTIALIAS)
            processed_path = f'processed/sticker_{sticker_number}.png'
            img.save(processed_path, 'PNG')

            context.user_data['image_files'][sticker_number] = processed_path
            await update.message.reply_text('–§–æ—Ç–æ –∑–∞–º–µ–Ω–µ–Ω–æ. –í—Å–µ –≥–æ—Ç–æ–≤–æ? –í—ã–±–µ—Ä–∏—Ç–µ: –ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë –∏–ª–∏ –ì–æ—Ç–æ–≤–æ.', reply_markup=InlineKeyboardMarkup([
                [
                    InlineKeyboardButton("–ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë", callback_data='edit_more'),
                    InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='edit_done')
                ]
            ]))
            return EDITING_STICKERS

        elif (update.message.video or update.message.document) and edit_type == 'video':
            video_idx = sticker_number - len(context.user_data['image_files'])
            file = await context.bot.get_file(update.message.video.file_id if update.message.video else update.message.document.file_id)
            file_extension = '.mp4' if update.message.video else os.path.splitext(update.message.document.file_name)[1]
            file_path = f'videos/sticker_{video_idx}{file_extension}'
            await file.download_to_drive(file_path)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
            converted_path = f'videos/sticker_{video_idx}.webm'
            process_video(file_path, converted_path)

            context.user_data['video_files'][video_idx] = converted_path

            await update.message.reply_text('–í–∏–¥–µ–æ –∑–∞–º–µ–Ω–µ–Ω–æ. –í—Å–µ –≥–æ—Ç–æ–≤–æ? –í—ã–±–µ—Ä–∏—Ç–µ: –ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë –∏–ª–∏ –ì–æ—Ç–æ–≤–æ.', reply_markup=InlineKeyboardMarkup([
                [
                    InlineKeyboardButton("–ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë", callback_data='edit_more'),
                    InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='edit_done')
                ]
            ]))
            return EDITING_STICKERS

        else:
            await update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–∏–ø–∞.')
            return EDITING_STICKERS
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –≤ handle_new_sticker: {str(e)}", traceback.format_exc())
        await update.message.reply_text('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ —Å—Ç–∏–∫–µ—Ä–∞.')
        return EDITING_STICKERS


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –≤ webm
def process_video(input_path, output_path):
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ
        clip = VideoFileClip(input_path)

        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 3 —Å–µ–∫—É–Ω–¥
        if clip.duration > 3:
            clip = clip.subclip(0, 3)

        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–±–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
        max_dimension = max(clip.w, clip.h)
        if max_dimension > 512:
            scale_factor = 512 / max_dimension
            clip = clip.resize(scale_factor)
        # –ï—Å–ª–∏ –æ–±–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è <= 512, –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ WebM —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, —É–±–∏—Ä–∞—è –∞—É–¥–∏–æ–∫–æ–¥–µ–∫
        clip.write_videofile(
            output_path,
            codec="libvpx-vp9",      # –ö–æ–¥–µ–∫ VP9 –¥–ª—è –≤–∏–¥–µ–æ
            bitrate="256k",          # –ë–∏—Ç—Ä–µ–π—Ç
            ffmpeg_params=["-crf", "30", "-pix_fmt", "yuva420p"]  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        )

    except Exception as e:
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {str(e)}", traceback.format_exc())
        raise  # –ü–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏



# handlers/create.py

# handlers/create.py

def is_valid_video(video_path: str) -> (bool, str):
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        max_size = 512 * 1024  # 512 KB
        file_size = os.path.getsize(video_path)
        if file_size > max_size:
            return False, f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {file_size} –±–∞–π—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π 512 –ö–ë."

        # –û—Ç–∫—Ä—ã—Ç–∏–µ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é moviepy
        with VideoFileClip(video_path) as clip:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            duration = clip.duration
            if duration > 3.0:
                return False, f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ {duration} —Å–µ–∫—É–Ω–¥ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã."

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –≤–∏–¥–µ–æ
            width, height = clip.size
            if width > 512 or height > 512:
                return False, f"–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤–∏–¥–µ–æ {width}x{height} –ø–∏–∫—Å–µ–ª–µ–π –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ 512x512."

        return True, ""
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≤–∏–¥–µ–æ: {str(e)}")
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≤–∏–¥–µ–æ: {str(e)}"

from moviepy.editor import ImageClip, VideoFileClip

def resize_clip(clip: VideoFileClip) -> VideoFileClip:
    """
    –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–∏ —à–∏—Ä–∏–Ω–∞, –Ω–∏ –≤—ã—Å–æ—Ç–∞ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–ª–∏ 512 –ø–∏–∫—Å–µ–ª–µ–π,
    —Å–æ—Ö—Ä–∞–Ω—è—è —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω.
    """
    max_dimension = max(clip.w, clip.h)
    if max_dimension > 512:
        scale_factor = 512 / max_dimension
        return resize_clip(clip)
    return clip

from moviepy.editor import ImageClip

def convert_image_to_webm(input_image_path: str, output_video_path: str) -> str:
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ ImageClip
        clip = ImageClip(input_image_path)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ (3 —Å–µ–∫—É–Ω–¥—ã)
        clip = clip.set_duration(3)

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–∏ —à–∏—Ä–∏–Ω–∞, –Ω–∏ –≤—ã—Å–æ—Ç–∞ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–ª–∏ 512 –ø–∏–∫—Å–µ–ª–µ–π
        clip = resize_clip(clip)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∫–∞–¥—Ä–æ–≤ –¥–æ 30 FPS
        clip = clip.set_fps(30)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ WebM —Å –∫–æ–¥–µ–∫–æ–º VP9 –∏ –±–µ–∑ –∑–≤—É–∫–∞
        clip.write_videofile(
            output_video_path,
            codec='libvpx-vp9',        # –ö–æ–¥–µ–∫ VP9
            audio=False,               # –û—Ç–∫–ª—é—á–∞–µ–º –∑–≤—É–∫
            threads=12,                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            preset='medium',           # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞/—Å–∫–æ—Ä–æ—Å—Ç–∏
            ffmpeg_params=['-pix_fmt', 'yuva420p']  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª
        )

        # –ü–æ–ª—É—á–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        props = get_video_properties(output_video_path)
        log_info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {props}")

        return output_video_path
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ WebM: {str(e)}")
        raise




# handlers/create.py

async def prepare_stickers_for_pack(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ
    invalid_videos = []
    for video_path in context.user_data.get('video_files', []):
        is_valid, reason = is_valid_video(video_path)
        if not is_valid:
            invalid_videos.append((video_path, reason))

    if invalid_videos:
        context.user_data['invalid_videos'] = invalid_videos
        # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏
        messages = [f"{os.path.basename(path)}: {reason}" for path, reason in invalid_videos]
        message_text = f"{len(invalid_videos)} —Ñ–∞–π–ª–æ–≤ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —É—Å–ª–æ–≤–∏—è–º:\n" + "\n".join(messages)
        await update.effective_message.reply_text(message_text)
        await show_video_validation_menu(update, context)
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –≤–∏–¥–µ–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –≤–∏–¥–µ–æ—Å—Ç–∏–∫–µ—Ä—ã
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    emojis = context.user_data.get('emojis', [])

    if video_files and image_files:  # –ï—Å–ª–∏ –µ—Å—Ç—å –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏ –≤–∏–¥–µ–æ, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for idx, image_path in enumerate(image_files):
            output_path = image_path.replace('.png', '_converted.webm')
            try:
                convert_image_to_webm(image_path, output_path)
                video_files.append(output_path)
                # –õ–æ–≥–∏—Ä—É–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
                props = get_video_properties(output_path)
                log_info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {props}")
            except Exception as e:
                log_error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_path} –≤ WebM: {str(e)}")
                continue

        # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –∑–∞–º–µ–Ω–µ–Ω—ã –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞–º–∏
        image_files.clear()

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–æ–≤ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if image_files:
        await create_sticker_pack(update, context, image_files, emojis[:len(image_files)], 'static')

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ
    if video_files:
        await create_sticker_pack(update, context, video_files, emojis[len(image_files):], 'video')

    # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    context.user_data.clear()

# handlers/create.py

def get_video_properties(video_path: str) -> dict:
    try:
        with VideoFileClip(video_path) as clip:
            return {
                'duration': clip.duration,
                'width': clip.w,
                'height': clip.h,
                'fps': clip.fps,
                'file_size': os.path.getsize(video_path)
            }
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–∏–¥–µ–æ: {str(e)}")
        return {}



async def show_video_validation_menu(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['current_invalid_video'] = 0
    await show_current_invalid_video(update, context)
    return VIDEO_VALIDATION

# handlers/create.py

async def show_current_invalid_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data.get('current_invalid_video', 0)
    invalid_videos = context.user_data.get('invalid_videos', [])
    if idx < 0 or idx >= len(invalid_videos):
        await update.effective_message.reply_text("–ù–µ—Ç –±–æ–ª—å—à–µ –≤–∏–¥–µ–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    video_path, reason = invalid_videos[idx]
    video_filename = os.path.basename(video_path)
    total_videos = len(invalid_videos)

    with open(video_path, 'rb') as video_file:
        await context.bot.send_video(
            chat_id=update.effective_chat.id,
            video=video_file,
            caption=f"–í–∏–¥–µ–æ {idx + 1} –∏–∑ {total_videos}: {video_filename}\n–ü—Ä–∏—á–∏–Ω–∞: {reason}"
        )

    keyboard = [
        [
            InlineKeyboardButton("‚¨ÖÔ∏è", callback_data='prev_invalid_video'),
            InlineKeyboardButton("‚û°Ô∏è", callback_data='next_invalid_video')
        ],
        [
            InlineKeyboardButton("‚úÇÔ∏è", callback_data='trim_current_video'),
            InlineKeyboardButton("‚úÇÔ∏è‚úÇÔ∏è", callback_data='trim_all_videos')
        ],
        [
            InlineKeyboardButton("üóëÔ∏è", callback_data='delete_current_video'),
            InlineKeyboardButton("üîô", callback_data='back_to_previous_menu')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)

# handlers/create.py

async def handle_video_validation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    log_info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è: {data}")
    if data == 'trim_current_video':
        await trim_current_video(update, context)
    elif data == 'trim_all_videos':
        await trim_all_videos(update, context)
    elif data == 'delete_current_video':
        await delete_current_video(update, context)
    elif data == 'prev_invalid_video':
        await show_prev_invalid_video(update, context)
    elif data == 'next_invalid_video':
        await show_next_invalid_video(update, context)
    elif data == 'back_to_previous_menu':
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –º–µ–Ω—é
        await prepare_stickers_for_pack(update, context)
        return ConversationHandler.END
    return VIDEO_VALIDATION


async def show_video_validation_menu(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['current_invalid_video'] = 0
    await show_current_invalid_video(update, context)
    return VIDEO_VALIDATION

async def handle_video_validation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    if data == 'trim_current_video':
        await trim_current_video(update, context)
    elif data == 'trim_all_videos':
        await trim_all_videos(update, context)
    elif data == 'delete_current_video':
        await delete_current_video(update, context)
    elif data == 'prev_invalid_video':
        await show_prev_invalid_video(update, context)
    elif data == 'next_invalid_video':
        await show_next_invalid_video(update, context)
    elif data == 'back_to_previous_menu':
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –º–µ–Ω—é
        await prepare_stickers_for_pack(update, context)
        return ConversationHandler.END
    return VIDEO_VALIDATION

async def trim_current_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data.get('current_invalid_video', 0)
    invalid_videos = context.user_data.get('invalid_videos', [])
    if idx < 0 or idx >= len(invalid_videos):
        await update.effective_message.reply_text("–ù–µ—Ç –≤–∏–¥–µ–æ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏.")
        return

    video_path = invalid_videos[idx]
    await update.effective_message.reply_text("–û–±—Ä–µ–∑–∫–∞ –≤–∏–¥–µ–æ, –æ–∂–∏–¥–∞–π—Ç–µ...")
    new_video_path = await trim_video(video_path)

    # –ó–∞–º–µ–Ω—è–µ–º –≤–∏–¥–µ–æ –≤ —Å–ø–∏—Å–∫–∞—Ö
    context.user_data['video_files'].append(new_video_path)
    invalid_videos.pop(idx)

    if not invalid_videos:
        # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –Ω–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –≤–∏–¥–µ–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        await update.effective_message.reply_text("–í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
        await prepare_stickers_for_pack(update, context)
        return

    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ –≤–∏–¥–µ–æ
        if idx >= len(invalid_videos):
            context.user_data['current_invalid_video'] = len(invalid_videos) - 1
        await show_current_invalid_video(update, context)

async def trim_all_videos(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    invalid_videos = context.user_data.get('invalid_videos', [])
    await update.effective_message.reply_text("–û–±—Ä–µ–∑–∫–∞ –≤—Å–µ—Ö –≤–∏–¥–µ–æ, –æ–∂–∏–¥–∞–π—Ç–µ...")
    for video_path in invalid_videos:
        new_video_path = await trim_video(video_path)
        context.user_data['video_files'].append(new_video_path)
    # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –≤–∏–¥–µ–æ
    context.user_data['invalid_videos'] = []
    await update.effective_message.reply_text("–í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
    await prepare_stickers_for_pack(update, context)

async def delete_current_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data.get('current_invalid_video', 0)
    invalid_videos = context.user_data.get('invalid_videos', [])
    if idx < 0 or idx >= len(invalid_videos):
        await update.effective_message.reply_text("–ù–µ—Ç –≤–∏–¥–µ–æ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
        return

    video_path = invalid_videos.pop(idx)
    # –ù–µ —É–¥–∞–ª—è–µ–º —Ñ–∏–∑–∏—á–µ—Å–∫–∏ —Ñ–∞–π–ª, –Ω–æ —É–¥–∞–ª—è–µ–º –∏–∑ —Å–ø–∏—Å–∫–æ–≤
    await update.effective_message.reply_text("–í–∏–¥–µ–æ —É–¥–∞–ª–µ–Ω–æ –∏–∑ —Å–ø–∏—Å–∫–∞.")
    if not invalid_videos:
        await update.effective_message.reply_text("–í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
        await prepare_stickers_for_pack(update, context)
        return
    else:
        if idx >= len(invalid_videos):
            context.user_data['current_invalid_video'] = len(invalid_videos) - 1
        await show_current_invalid_video(update, context)

async def show_prev_invalid_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data['current_invalid_video'] -= 1
    if context.user_data['current_invalid_video'] < 0:
        context.user_data['current_invalid_video'] = 0
    await show_current_invalid_video(update, context)

async def show_next_invalid_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data['current_invalid_video'] += 1
    invalid_videos = context.user_data.get('invalid_videos', [])
    if context.user_data['current_invalid_video'] >= len(invalid_videos):
        context.user_data['current_invalid_video'] = len(invalid_videos) - 1
    await show_current_invalid_video(update, context)

from ffmpeg import _ffmpeg
async def trim_video(video_path: str) -> str:
    try:
        output_path = video_path.replace('.mp4', '_trimmed.mp4')
        (
            _ffmpeg
            .input(video_path)
            .output(output_path, ss=0, t=3, c='copy')  # –û–±—Ä–µ–∑–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å–µ–∫—É–Ω–¥
            .run(overwrite_output=True)
        )
        return output_path
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–µ–∑–∫–µ –≤–∏–¥–µ–æ: {str(e)}")
        return video_path  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ, –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å

async def process_media_menu(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['current_media_index'] = 0
    await show_current_media_selection_menu(update, context)
    return PROCESSING_MEDIA

async def show_current_media_selection_menu(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data.get('current_media_index', 0)
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    total_media = len(image_files) + len(video_files)

    if idx < 0 or idx >= total_media:
        await update.effective_message.reply_text("–ù–µ—Ç –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    if idx < len(image_files):
        media_type = 'image'
        media_path = image_files[idx]
        with open(media_path, 'rb') as img:
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=img,
                caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1} –∏–∑ {total_media}"
            )
    else:
        media_type = 'video'
        video_idx = idx - len(image_files)
        media_path = video_files[video_idx]
        with open(media_path, 'rb') as video_file:
            await context.bot.send_video(
                chat_id=update.effective_chat.id,
                video=video_file,
                caption=f"–í–∏–¥–µ–æ {video_idx + 1} –∏–∑ {total_media}"
            )

    keyboard = [
        [
            InlineKeyboardButton("‚¨ÖÔ∏è", callback_data='prev_media'),
            InlineKeyboardButton("‚û°Ô∏è", callback_data='next_media')
        ],
        [
            InlineKeyboardButton("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å", callback_data='process_current_media'),
            InlineKeyboardButton("–ù–∞–∑–∞–¥", callback_data='back_to_previous_menu')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)


async def handle_media_navigation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    if data == 'prev_media':
        context.user_data['current_media_index'] -= 1
        if context.user_data['current_media_index'] < 0:
            context.user_data['current_media_index'] = 0
        await show_current_media_selection_menu(update, context)
    elif data == 'next_media':
        context.user_data['current_media_index'] += 1
        image_files = context.user_data.get('image_files', [])
        video_files = context.user_data.get('video_files', [])
        total_media = len(image_files) + len(video_files)
        if context.user_data['current_media_index'] >= total_media:
            context.user_data['current_media_index'] = total_media - 1
        await show_current_media_selection_menu(update, context)
    elif data == 'back_to_previous_menu':
        await query.edit_message_text("–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –º–µ–Ω—é.")
        # –ó–¥–µ—Å—å –≤—ã–∑—ã–≤–∞–µ–º –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
        return PROCESSING_STICKERS
    elif data == 'process_current_media':
        await process_current_media(update, context)
    else:
        await query.edit_message_text("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞.")

    return PROCESSING_MEDIA

async def process_current_media(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    idx = context.user_data.get('current_media_index', 0)
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    total_media = len(image_files) + len(video_files)

    if idx < 0 or idx >= total_media:
        await query.edit_message_text("–ù–µ—Ç –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return PROCESSING_MEDIA

    if idx < len(image_files):
        media_type = 'image'
        media_path = image_files[idx]
        processed_variants = await process_image_variants(media_path)
    else:
        media_type = 'video'
        video_idx = idx - len(image_files)
        media_path = video_files[video_idx]
        processed_variants = await process_video_variants(media_path)

    if not processed_variants:
        await query.edit_message_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–∏–∞—Ñ–∞–π–ª.")
        return PROCESSING_MEDIA

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∫–∞–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
    keyboard = [
        [InlineKeyboardButton("–í–∞—Ä–∏–∞–Ω—Ç 1", callback_data=f'select_variant_0')],
        [InlineKeyboardButton("–í–∞—Ä–∏–∞–Ω—Ç 2", callback_data=f'select_variant_1')],
        [InlineKeyboardButton("–í–∞—Ä–∏–∞–Ω—Ç 3", callback_data=f'select_variant_2')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    for variant_path in processed_variants:
        if media_type == 'image':
            with open(variant_path, 'rb') as img:
                await context.bot.send_photo(
                    chat_id=update.effective_chat.id,
                    photo=img,
                    caption="–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
                )
        else:
            with open(variant_path, 'rb') as video_file:
                await context.bot.send_video(
                    chat_id=update.effective_chat.id,
                    video=video_file,
                    caption="–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ"
                )

    await query.edit_message_text("–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç:", reply_markup=reply_markup)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç–∏ –∫ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã–±–æ—Ä–∞
    context.user_data['processed_variants'] = processed_variants

    return PROCESSING_MEDIA

async def process_image_variants(image_path: str) -> list:
    try:
        # –°–æ–∑–¥–∞—ë–º —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞–º–∏
        briaai_path = image_path.replace('.png', '_briaai.png')
        rembg_path = image_path.replace('.png', '_rembg.png')
        u2net_path = image_path.replace('.png', '_u2net.png')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é BriaAI
        remove_background_briaai(image_path, briaai_path)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é RemBG
        remove_background_from_image(image_path, rembg_path)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é U2Net
        mask = remove_background_u2net(image_path, u2net_model)
        save_u2net_result(image_path, mask, u2net_path)

        return [briaai_path, rembg_path, u2net_path]
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {str(e)}", traceback.format_exc())
        return []

async def process_video_variants(video_path: str) -> list:
    try:
        # –°–æ–∑–¥–∞—ë–º —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞–º–∏
        variant1 = video_path.replace('.webm', '_variant1.webm')
        variant2 = video_path.replace('.webm', '_variant2.webm')
        variant3 = video_path.replace('.webm', '_variant3.webm')

        # –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏: –æ–±—Ä–µ–∑–∫–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ —Ç.–¥.
        # –ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–∑–≤–∞—Ç—å —Å–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø—Ä–∏–≤–µ–¥—É –ø—Ä–∏–º–µ—Ä –æ–±—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ –¥–æ 3 —Å–µ–∫—É–Ω–¥
        await convert_mp4_to_webm(video_path, variant1)  # –£–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        # –°–æ–∑–¥–∞–π—Ç–µ –¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        # variant2, variant3

        return [variant1]  # –î–æ–±–∞–≤—å—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ {video_path}: {str(e)}", traceback.format_exc())
        return []

async def handle_variant_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    match = re.match(r'select_variant_(\d+)', data)
    if not match:
        await query.edit_message_text("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞.")
        return PROCESSING_MEDIA

    variant_index = int(match.group(1))
    processed_variants = context.user_data.get('processed_variants', [])

    if variant_index < 0 or variant_index >= len(processed_variants):
        await query.edit_message_text("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≤–∞—Ä–∏–∞–Ω—Ç–∞.")
        return PROCESSING_MEDIA

    selected_variant_path = processed_variants[variant_index]

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –≤ —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –≤–∏–¥–µ–æ
    current_index = context.user_data.get('current_media_index', 0)
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])

    if current_index < len(image_files):
        image_files[current_index] = selected_variant_path
    else:
        video_idx = current_index - len(image_files)
        video_files[video_idx] = selected_variant_path

    context.user_data['image_files'] = image_files
    context.user_data['video_files'] = video_files

    await query.edit_message_text("–í–∞—Ä–∏–∞–Ω—Ç –≤—ã–±—Ä–∞–Ω. –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫.")

    # –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫ –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
    keyboard = [
        [
            InlineKeyboardButton("–°–æ–∑–¥–∞—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫", callback_data='create_pack'),
            InlineKeyboardButton("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", callback_data='continue_processing')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await query.message.reply_text("–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ?", reply_markup=reply_markup)

    return PROCESSING_MEDIA



async def show_current_media(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data.get('current_media_index', 0)
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    total_media = len(image_files) + len(video_files)

    if idx < 0 or idx >= total_media:
        await update.effective_message.reply_text("–ù–µ—Ç –±–æ–ª—å—à–µ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    if idx < len(image_files):
        media_type = 'image'
        media_path = image_files[idx]
        with open(media_path, 'rb') as img:
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=img,
                caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1} –∏–∑ {total_media}"
            )
    else:
        media_type = 'video'
        video_idx = idx - len(image_files)
        media_path = video_files[video_idx]
        with open(media_path, 'rb') as video_file:
            await context.bot.send_video(
                chat_id=update.effective_chat.id,
                video=video_file,
                caption=f"–í–∏–¥–µ–æ {video_idx + 1} –∏–∑ {total_media}"
            )

    context.user_data['current_media_type'] = media_type
    context.user_data['current_media_path'] = media_path

    keyboard = []
    if media_type == 'image':
        keyboard.append([
            InlineKeyboardButton("‚¨ÖÔ∏è", callback_data='prev_media'),
            InlineKeyboardButton("‚û°Ô∏è", callback_data='next_media')
        ])
    else:
        keyboard.append([
            InlineKeyboardButton("–í—ã—Ä–µ–∑–∞—Ç—å –æ–±—ä–µ–∫—Ç –Ω–∞ –≤–∏–¥–µ–æ", callback_data='process_video'),
            InlineKeyboardButton("–û–±—Ä–µ–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 —Å–µ–∫—É–Ω–¥ –≤–∏–¥–µ–æ", callback_data='trim_video')
        ])
    keyboard.append([
        InlineKeyboardButton("–ù–∞–∑–∞–¥", callback_data='back_to_previous_menu'),
        InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_processing')
    ])
    keyboard.append([
        InlineKeyboardButton("–ù–∞–∑–∞–¥", callback_data='prev_media'),
        InlineKeyboardButton("–î–∞–ª–µ–µ", callback_data='next_media')
    ])
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)

def resize_video(clip: VideoFileClip) -> VideoFileClip:
    max_dimension = max(clip.w, clip.h)
    if max_dimension > 512:
        scale_factor = 512 / max_dimension
        return clip.resize(scale_factor)
    return clip


async def process_current_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–∂–∏–¥–∞–π—Ç–µ...")
    video_path = context.user_data.get('current_media_path')
    output_path = video_path.replace('.webm', '_processed.webm')

    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        with VideoFileClip(video_path) as clip:
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 3 —Å–µ–∫—É–Ω–¥, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if clip.duration > 3:
                clip = clip.subclip(0, 3)

            # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–±–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
            max_dimension = max(clip.w, clip.h)
            if max_dimension > 512:
                scale_factor = 512 / max_dimension
                clip = clip.resize(scale_factor)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
            clip.write_videofile(
                output_path,
                codec="libvpx-vp9",
                bitrate="256k",
                ffmpeg_params=["-crf", "30", "-pix_fmt", "yuva420p"]
            )

        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–¥–µ–æ –≤ user_data
        idx = context.user_data.get('current_media_index') - len(context.user_data.get('image_files', []))
        context.user_data['video_files'][idx] = output_path

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ —Å –∫–Ω–æ–ø–∫–∞–º–∏
        with open(output_path, 'rb') as vid:
            await context.bot.send_video(
                chat_id=update.effective_chat.id,
                video=vid,
                caption="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='video_processing_done')],
                    [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_video_processing')]
                ])
            )
    except Exception as e:
        await update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –≤–∏–¥–µ–æ.')
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}")
        return PROCESSING_STICKERS



async def handle_media_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    data = query.data
    if data == 'process_image':
        await process_current_image(update, context)
    elif data == 'process_all_images':
        await process_all_images(update, context)
    elif data == 'process_video':
        await process_current_video(update, context)
    elif data == 'trim_video':
        await trim_current_video(update, context)
    elif data == 'prev_media':
        context.user_data['current_media_index'] -= 1
        if context.user_data['current_media_index'] < 0:
            context.user_data['current_media_index'] = 0
        await show_current_media(update, context)
    elif data == 'next_media':
        context.user_data['current_media_index'] += 1
        total_media = len(context.user_data.get('image_files', [])) + len(context.user_data.get('video_files', []))
        if context.user_data['current_media_index'] >= total_media:
            context.user_data['current_media_index'] = total_media - 1
        await show_current_media(update, context)
    elif data == 'back_to_previous_menu':
        await prepare_stickers_for_pack(update, context)
        return ConversationHandler.END
    elif data == 'process_with_briaai':
        await process_image_with_briaai(update, context)
    elif data == 'process_with_rembg':
        await process_image_with_rembg(update, context)
    elif data == 'process_with_u2net':
        await process_image_with_u2net(update, context)
    elif data == 'image_processing_done':
        await update.effective_message.reply_text("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ.")
        await show_current_media(update, context)
        return PROCESSING_MEDIA
    elif data == 'cancel_image_processing':
        await update.effective_message.reply_text("–ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–º–µ–Ω–µ–Ω—ã.")
        await show_current_media(update, context)
    elif data == 'video_processing_done':
        await update.effective_message.reply_text("–í–∏–¥–µ–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ.")
        await show_current_media(update, context)
        return PROCESSING_MEDIA
    elif data == 'cancel_video_processing':
        await update.effective_message.reply_text("–ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–º–µ–Ω–µ–Ω—ã.")
        await show_current_media(update, context)
    elif data == 'cancel_all_images_processing':
        await cancel_all_images_processing(update, context)
        return PROCESSING_MEDIA


async def process_all_images(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–±—Ä–µ–∑–∫–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ–∂–∏–¥–∞–π—Ç–µ...")
    image_files = context.user_data.get('image_files', [])
    processed_files = []
    for idx, image_path in enumerate(image_files):
        output_path = image_path.replace('.png', '_processed.png')
        # –í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –ø–æ –æ—á–µ—Ä–µ–¥–∏
        remove_background_briaai(image_path, output_path)
        processed_files.append(output_path)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å–ª—É—á–∞–π –æ—Ç–º–µ–Ω—ã
    context.user_data['original_image_files'] = image_files.copy()
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ user_data
    context.user_data['image_files'] = processed_files
    await update.effective_message.reply_text("–í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.", reply_markup=InlineKeyboardMarkup([
        [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_all_images_processing')]
    ]))

async def cancel_all_images_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    context.user_data['image_files'] = context.user_data['original_image_files']
    del context.user_data['original_image_files']
    await update.effective_message.reply_text("–ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–º–µ–Ω–µ–Ω—ã.")
    await show_current_media(update, context)

def process_image_with_rembg_tool(image_path):
    rembg_path = image_path.replace('.png', '_rembg.png')
    remove_background_from_image(image_path)
    return rembg_path

def process_image_with_u2net_tool(image_path):
    u2net_path = image_path.replace('.png', '_u2net.png')
    mask = remove_background_u2net(image_path, u2net_model)
    save_u2net_result(image_path, mask, u2net_path)
    return u2net_path

# –ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é RemBG
async def process_current_image(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é –æ–±—Ä–µ–∑–∫–∏:", reply_markup=InlineKeyboardMarkup([
        [
            InlineKeyboardButton("BriaAI", callback_data='process_with_briaai'),
            InlineKeyboardButton("RemBG", callback_data='process_with_rembg'),
            InlineKeyboardButton("U2Net", callback_data='process_with_u2net')
        ],
        [
            InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_image_processing')
        ]
    ]))
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    context.user_data['processing_image_path'] = context.user_data.get('current_media_path')
    context.user_data['processing_image_index'] = context.user_data.get('current_media_index')

async def process_image_with_briaai(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–∂–∏–¥–∞–π—Ç–µ...")

    image_path = context.user_data.get('processing_image_path')
    output_path = image_path.replace('.png', '_briaai.png')
    remove_background_briaai(image_path, output_path)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ user_data
    idx = context.user_data.get('processing_image_index')
    context.user_data['image_files'][idx] = output_path

    await update.effective_message.reply_text("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.", reply_markup=InlineKeyboardMarkup([
        [InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='image_processing_done')],
        [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_image_processing')]
    ]))

async def show_current_invalid_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    idx = context.user_data['current_invalid_video']
    video_path = context.user_data['invalid_videos'][idx]
    with open(video_path, 'rb') as video_file:
        await context.bot.send_video(
            chat_id=update.effective_chat.id,
            video=video_file,
            caption=f"–í–∏–¥–µ–æ {idx + 1} –∏–∑ {len(context.user_data['invalid_videos'])}"
        )

    keyboard = [
        [
            InlineKeyboardButton("–û–±—Ä–µ–∑–∞—Ç—å –≤–∏–¥–µ–æ –ø–æ 5 —Å–µ–∫—É–Ω–¥ –≤ –Ω–∞—á–∞–ª–µ", callback_data='trim_current_video'),
            InlineKeyboardButton("–û–±—Ä–µ–∑–∞—Ç—å –≤—Å–µ –≤–∏–¥–µ–æ", callback_data='trim_all_videos')
        ],
        [
            InlineKeyboardButton("–£–¥–∞–ª–∏—Ç—å", callback_data='delete_current_video'),
            InlineKeyboardButton("–ù–∞–∑–∞–¥", callback_data='back_to_previous_menu')
        ],
        [
            InlineKeyboardButton("‚¨ÖÔ∏è", callback_data='prev_invalid_video'),
            InlineKeyboardButton("‚û°Ô∏è", callback_data='next_invalid_video')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.effective_message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)

async def handle_pack_name(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    message_text = update.message.text
    if not is_english(message_text):
        await update.message.reply_text('–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–Ω–æ–≤–∞.')
        return AWAITING_PACK_NAME
    context.user_data['pack_name'] = message_text
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–º—è –∞–≤—Ç–æ—Ä–∞ –∫–∞–∫ username –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user = update.effective_user
    context.user_data['author_name'] = user.username or user.full_name
    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –æ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
    keyboard = [
        [InlineKeyboardButton("–ü—Ä–∏–≤–∞—Ç–Ω—ã–π", callback_data='private')],
        [InlineKeyboardButton("–ü—É–±–ª–∏—á–Ω—ã–π", callback_data='public')],
        [InlineKeyboardButton("–ù–∞–∑–∞–¥", callback_data='back_to_main')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–°–¥–µ–ª–∞—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫ –ø—Ä–∏–≤–∞—Ç–Ω—ã–º –∏–ª–∏ –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–º?', reply_markup=reply_markup)
    return AWAITING_PRIVACY

async def handle_privacy_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    if query.data == 'private':
        context.user_data['is_private'] = True
    elif query.data == 'public':
        context.user_data['is_private'] = False
    elif query.data == 'back_to_main':
        await ask_for_pack_name(update, context)
        return AWAITING_PACK_NAME
    else:
        await query.edit_message_text('–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞.')
        return AWAITING_PRIVACY
    await query.edit_message_text('–°–ø–∞—Å–∏–±–æ! –í–∞—à —Å—Ç–∏–∫–µ—Ä–ø–∞–∫ —Å–æ–∑–¥–∞–µ—Ç—Å—è.')
    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞
    await prepare_stickers_for_pack(update, context)
    return ConversationHandler.END

async def create_sticker_pack(update, context, sticker_files, emojis, sticker_format):
    user_id = update.effective_user.id
    pack_name_base = context.user_data.get('pack_name')
    pack_name = sanitize_pack_name(f"{pack_name_base}_{sticker_format}", BOT_USERNAME)
    author_name = context.user_data.get('author_name')
    is_private = context.user_data.get('is_private', True)

    # –î–æ–ø–æ–ª–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —ç–º–æ–¥–∑–∏, –µ—Å–ª–∏ –∏—Ö –º–µ–Ω—å—à–µ, —á–µ–º —Å—Ç–∏–∫–µ—Ä–æ–≤
    while len(emojis) < len(sticker_files):
        emojis.append(random.choice(RANDOM_EMOJIS))

    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–∏–∫–µ—Ä–ø–∞–∫ —Å –ø–µ—Ä–≤—ã–º —Å—Ç–∏–∫–µ—Ä–æ–º
        first_sticker_path = sticker_files[0]
        first_emoji = emojis[0]
        with open(first_sticker_path, 'rb') as sticker_file:
            if sticker_format == 'video':
                first_sticker = InputSticker(
                    sticker=sticker_file,
                    emoji_list=[first_emoji],
                    mask_position=None,
                    keywords=None,
                    format='video'  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –≤–∏–¥–µ–æ
                )
            else:
                first_sticker = InputSticker(
                    sticker=sticker_file,
                    emoji_list=[first_emoji],
                    mask_position=None,
                    keywords=None,
                    format = 'static'
                )
            await context.bot.create_new_sticker_set(
                user_id=user_id,
                name=pack_name,
                title=pack_name_base,
                stickers=[first_sticker]
            )
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞: {str(e)}", traceback.format_exc())
        await update.effective_message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Å—Ç–∏–∫–µ—Ä–ø–∞–∫.')
        return

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–∏–∫–µ—Ä—ã
    for idx in range(1, len(sticker_files)):
        sticker_path = sticker_files[idx]
        emoji_assigned = emojis[idx]
        with open(sticker_path, 'rb') as sticker_file:
            try:
                if sticker_format == 'video':
                    sticker = InputSticker(
                        sticker=sticker_file,
                        emoji_list=[emoji_assigned],
                        mask_position=None,
                        keywords=None,
                        format='video'
                    )
                else:
                    sticker = InputSticker(
                        sticker=sticker_file,
                        emoji_list=[emoji_assigned],
                        mask_position=None,
                        keywords=None,
                        format='static'
                    )
                await context.bot.add_sticker_to_set(
                    user_id=user_id,
                    name=pack_name,
                    sticker=sticker
                )
                await asyncio.sleep(0.5)  # –ò–∑–±–µ–≥–∞–µ–º –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
            except Exception as e:
                log_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Ç–∏–∫–µ—Ä–∞: {str(e)}", traceback.format_exc())
                await update.effective_message.reply_text(f'–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç–∏–∫–µ—Ä {idx + 1}.')
                continue

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏
    pack_link = f'https://t.me/addstickers/{pack_name}'
    await update.effective_message.reply_text(
        f'–°—Ç–∏–∫–µ—Ä–ø–∞–∫ "{pack_name_base}" —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!\n–°—Å—ã–ª–∫–∞: {pack_link}'
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∏–∫–µ—Ä–ø–∞–∫ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    add_sticker_pack(user_id, pack_name_base, author_name, pack_link, is_private)



async def process_image_with_rembg(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–∂–∏–¥–∞–π—Ç–µ...")

    image_path = context.user_data.get('processing_image_path')
    output_path = image_path.replace('.png', '_rembg.png')

    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ rembg.py
    result_image = remove_background_from_image(image_path)
    result_image.save(output_path)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ user_data
    idx = context.user_data.get('processing_image_index')
    context.user_data['image_files'][idx] = output_path

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏
    with open(output_path, 'rb') as img:
        await context.bot.send_photo(
            chat_id=update.effective_chat.id,
            photo=img,
            caption="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='image_processing_done')],
                [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_image_processing')]
            ])
        )

async def process_image_with_u2net(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.effective_message.reply_text("–û–∂–∏–¥–∞–π—Ç–µ...")

    image_path = context.user_data.get('processing_image_path')
    output_path = image_path.replace('.png', '_u2net.png')

    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ u2net.py
    mask = remove_background_u2net(image_path, u2net_model)
    save_u2net_result(image_path, mask, output_path)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ user_data
    idx = context.user_data.get('processing_image_index')
    context.user_data['image_files'][idx] = output_path

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏
    with open(output_path, 'rb') as img:
        await context.bot.send_photo(
            chat_id=update.effective_chat.id,
            photo=img,
            caption="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='image_processing_done')],
                [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data='cancel_image_processing')]
            ])
        )



async def prompt_for_emoji(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    current = context.user_data.get('current_sticker_index', 0)
    image_files = context.user_data.get('image_files', [])
    video_files = context.user_data.get('video_files', [])
    sticker_files = image_files + video_files

    if current < len(sticker_files):
        sticker_path = sticker_files[current]
        if current < len(image_files):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            with open(sticker_path, 'rb') as img:
                await context.bot.send_photo(
                    chat_id=update.effective_chat.id,
                    photo=img,
                    caption=f'–ü—Ä–∏—à–ª–∏—Ç–µ —ç–º–æ–¥–∑–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–∞ {current + 1}/{len(sticker_files)}:',
                    reply_markup=InlineKeyboardMarkup([
                        [
                            InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data='skip'),
                            InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ", callback_data='skip_all')
                        ]
                    ])
                )
        else:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
            with open(sticker_path, 'rb') as video_file:
                await context.bot.send_video(
                    chat_id=update.effective_chat.id,
                    video=video_file,
                    caption=f'–ü—Ä–∏—à–ª–∏—Ç–µ —ç–º–æ–¥–∑–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–∞ {current + 1}/{len(sticker_files)}:',
                    reply_markup=InlineKeyboardMarkup([
                        [
                            InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data='skip'),
                            InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ", callback_data='skip_all')
                        ]
                    ])
                )
        return AWAITING_EMOJI
    else:
        await ask_for_pack_name(update, context)
        return AWAITING_PACK_NAME


async def handle_emoji(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    emoji_input = update.message.text.strip()

    if not is_valid_emoji(emoji_input):
        await update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–ø—É—Å—Ç–∏–º—ã–π —ç–º–æ–¥–∑–∏ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ "–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å".')
        return AWAITING_EMOJI

    context.user_data['emojis'].append(emoji_input)
    context.user_data['current_sticker_index'] += 1

    return await prompt_for_emoji(update, context)


async def handle_skip(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    if not RANDOM_EMOJIS:
        await update.callback_query.answer(text="–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è.", show_alert=True)
        return AWAITING_EMOJI

    random_emoji = random.choice(RANDOM_EMOJIS)
    context.user_data['emojis'].append(random_emoji)
    context.user_data['current_sticker_index'] += 1

    await update.callback_query.answer()
    return await prompt_for_emoji(update, context)


async def handle_skip_all(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    image_files = context.user_data.get('image_files', [])
    current = context.user_data.get('current_image', 0)

    while current < len(image_files):
        random_emoji = random.choice(RANDOM_EMOJIS)
        context.user_data['emojis'].append(random_emoji)
        current += 1

    context.user_data['current_image'] = current
    await update.callback_query.answer()
    await ask_for_pack_name(update, context)
    return AWAITING_PACK_NAME

def is_valid_emoji(s: str) -> bool:
    return s in emoji.EMOJI_DATA

async def ask_for_pack_name(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    await update.effective_message.reply_text('–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–∞ (—Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã):')
    return AWAITING_PACK_NAME

def is_english(text: str) -> bool:
    return all(ord(c) < 128 for c in text)

# –§—É–Ω–∫—Ü–∏–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π:

async def edit_photos(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    image_files = context.user_data.get('image_files', [])
    if not image_files:
        await update.effective_message.reply_text('–ù–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.')
        return PROCESSING_STICKERS

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–æ—Ç–æ —Å –Ω–æ–º–µ—Ä–∞–º–∏
    for idx, image_path in enumerate(image_files):
        with open(image_path, 'rb') as img:
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=img,
                caption=f'–§–æ—Ç–æ #{idx + 1}'
            )

    await update.effective_message.reply_text('–ö–∞–∫–æ–µ —Ñ–æ—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å? –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–æ—Ç–æ.')
    return EDITING_PHOTOS



async def handle_new_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        photo_number = context.user_data.get('photo_to_edit')
        if photo_number is None:
            await update.message.reply_text('–ù–µ –≤—ã–±—Ä–∞–Ω –Ω–æ–º–µ—Ä —Ñ–æ—Ç–æ –¥–ª—è –∑–∞–º–µ–Ω—ã.')
            return EDITING_PHOTOS

        file = await context.bot.get_file(update.message.photo[-1].file_id)
        file_path = f'images/photo_{photo_number}.jpg'
        await file.download_to_drive(file_path)

        img = Image.open(file_path)
        # –ò–∑–º–µ–Ω–µ–Ω–æ: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –∂–µ—Å—Ç–∫–æ–≥–æ –ø–æ–¥–≥–æ–Ω–∫–∏ –¥–æ 512x512
        img.thumbnail((512, 512), Image.ANTIALIAS)
        processed_path = f'processed/sticker_{photo_number}.png'
        img.save(processed_path, 'PNG')

        context.user_data['image_files'][photo_number] = processed_path
        await update.message.reply_text('–§–æ—Ç–æ –∑–∞–º–µ–Ω–µ–Ω–æ. –í—Å–µ –≥–æ—Ç–æ–≤–æ? –í—ã–±–µ—Ä–∏—Ç–µ: –ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë –∏–ª–∏ –ì–æ—Ç–æ–≤–æ.', reply_markup=InlineKeyboardMarkup([
            [
                InlineKeyboardButton("–ò–∑–º–µ–Ω–∏—Ç—å –µ—â—ë", callback_data='edit_more'),
                InlineKeyboardButton("–ì–æ—Ç–æ–≤–æ", callback_data='edit_done')
            ]
        ]))
        return EDITING_PHOTOS
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –≤ handle_new_photo: {str(e)}", traceback.format_exc())
        await update.message.reply_text('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏.')
        return EDITING_PHOTOS

async def handle_edit_options(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()

    if query.data == 'edit_more':
        await edit_photos(update, context)
        return EDITING_PHOTOS
    elif query.data == 'edit_done':
        context.user_data['current_image'] = 0
        await prompt_for_emoji(update, context)
        return AWAITING_EMOJI
    else:
        await query.edit_message_text('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞.')
        return EDITING_PHOTOS
